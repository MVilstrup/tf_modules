"""Contains model definitions for versions of the Oxford VGG network.

These model definitions were introduced in the following technical report:

  Very Deep Convolutional Networks For Large-Scale Image Recognition
  Karen Simonyan and Andrew Zisserman
  arXiv technical report, 2015
  PDF: http://arxiv.org/pdf/1409.1556.pdf
  ILSVRC 2014 Slides: http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf
  CC-BY-4.0

More information can be obtained from the VGG website:
www.robots.ox.ac.uk/~vgg/research/very_deep/

Usage:
  with slim.arg_scope(vgg.vgg_arg_scope()):
    outputs, end_points = vgg.vgg_a(inputs)

  with slim.arg_scope(vgg.vgg_arg_scope()):
    outputs, end_points = vgg.vgg_16(inputs)

@@vgg_a
@@vgg_16
@@vgg_19
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
from tf_modules.models import NewModel
from tf_modules.assertions.checks import *

slim = tf.contrib.slim


def vgg_arg_scope(weight_decay=0.0005):
    """Defines the VGG arg scope.

  Args:
    weight_decay: The l2 regularization coefficient.

  Returns:
    An arg_scope.
  """
    with slim.arg_scope([slim.conv2d, slim.fully_connected],
                        activation_fn=tf.nn.relu,
                        weights_regularizer=slim.l2_regularizer(weight_decay),
                        biases_initializer=tf.zeros_initializer()):
        with slim.arg_scope([slim.conv2d], padding='SAME') as arg_sc:
            return arg_sc


class VGG16_2(Model):
    def __init__(self, config, inputs, name='vgg_16', should_be_extended=True, reuse=None,
                 spatial_squeeze=True, scope='vgg_16', fc_conv_padding='VALID'):
        """Oxford Net VGG 16-Layers version D Example.

        Note: All the fully_connected layers have been transformed to conv2d layers.
            To use in classification mode, resize input to 224x224.

        Args:
            config: a configuration object
            inputs: a tensor of size [batch_size, height, width, channels].
            spatial_squeeze: whether or not should squeeze the spatial dimensions of the
                             outputs. Useful to remove unnecessary dimensions for classification.
            scope: Optional scope for the variables.
            fc_conv_padding: the type of padding to use for the fully connected layer
                             that is implemented as a convolutional layer. Use 'SAME' padding if you
                             are applying the network in a fully convolutional manner and want to
                             get a prediction map downsampled by a factor of 32 as an output.
                             Otherwise, the output prediction map will be (input / 32) - 6 in case of
                             'VALID' padding.

        Returns:
            the last op containing the log predictions and end_points dict.
        """
        Model.__init__(self, config, name=name, url='http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz')
        layer = self.internal_layer

        with slim.arg_scope(vgg_arg_scope()):
            with tf.variable_scope(scope, 'vgg_16', [inputs], reuse=reuse):
                net = layer('conv1', slim.repeat,     inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')
                net = layer('pool1', slim.max_pool2d, net, [2, 2], scope='pool1')
                net = layer('conv2', slim.repeat,     net, 2, slim.conv2d, 128, [3, 3], scope='conv2')
                net = layer('pool2', slim.max_pool2d, net, [2, 2], scope='pool2')
                net = layer('conv3', slim.repeat,     net, 3, slim.conv2d, 256, [3, 3], scope='conv3')
                net = layer('pool3', slim.max_pool2d, net, [2, 2], scope='pool3')
                net = layer('conv4', slim.repeat,     net, 3, slim.conv2d, 512, [3, 3], scope='conv4')
                net = layer('pool4', slim.max_pool2d, net, [2, 2], scope='pool4')
                net = layer('conv5', slim.repeat,     net, 3, slim.conv2d, 512, [3, 3], scope='conv5')
                net = layer('pool5', slim.max_pool2d, net, [2, 2], scope='pool5')

                # Use conv2d instead of fully_connected layers.
                net = layer('fc6', slim.conv2d, net, 4096, [7, 7], padding=fc_conv_padding, scope='fc6')
                net = layer('dropout6', slim.dropout, net, self.config.dropout,
                            is_training=self.config.is_training,
                            scope='dropout6')

                net = layer('fc7', slim.conv2d, net, 4096, [1, 1], scope='fc7')
                net = layer('dropout7', slim.dropout, net, self.config.dropout,
                            is_training=self.config.is_training,
                            scope='dropout7')

                if should_be_extended:
                    return

                net = layer('fc8', slim.conv2d, net, self.config.num_classes, [1, 1],
                            activation_fn=None,
                            normalizer_fn=None,
                            scope='fc8')

                # Convert end_points_collection into a end_point dict.
                if spatial_squeeze:
                    layer('fc8', tf.squeeze, net, [1, 2], name='fc8_squeezed')

class VGG19_2(Model):
    def __init__(self, config, inputs, name='vgg_19', should_be_extended=True, reuse=None, spatial_squeeze=True,
                 scope='vgg_19', fc_conv_padding='VALID'):
        """Oxford Net VGG 19-Layers.

        Note: All the fully_connected layers have been transformed to conv2d layers.
            To use in classification mode, resize input to 224x224.

        Args:
            config: a configuration object
            inputs: a tensor of size [batch_size, height, width, channels].
            spatial_squeeze: whether or not should squeeze the spatial dimensions of the
                             outputs. Useful to remove unnecessary dimensions for classification.
            scope: Optional scope for the variables.
            fc_conv_padding: the type of padding to use for the fully connected layer
                             that is implemented as a convolutional layer. Use 'SAME' padding if you
                             are applying the network in a fully convolutional manner and want to
                             get a prediction map downsampled by a factor of 32 as an output.
                             Otherwise, the output prediction map will be (input / 32) - 6 in case of
                             'VALID' padding.

        Returns:
            the last op containing the log predictions and end_points dict.
        """
        Model.__init__(self, config, name=name, url='http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz')
        layer = self.internal_layer

        with slim.arg_scope(vgg_arg_scope()):
            with tf.variable_scope(scope, 'vgg_19', [inputs], reuse=reuse):
                net = layer('conv1', slim.repeat,     inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')
                net = layer('pool1', slim.max_pool2d, net, [2, 2], scope='pool1')
                net = layer('conv2', slim.repeat,     net, 2, slim.conv2d, 128, [3, 3], scope='conv2')
                net = layer('pool2', slim.max_pool2d, net, [2, 2], scope='pool2')
                net = layer('conv3', slim.repeat,     net, 4, slim.conv2d, 256, [3, 3], scope='conv3')
                net = layer('pool3', slim.max_pool2d, net, [2, 2], scope='pool3')
                net = layer('conv4', slim.repeat,     net, 4, slim.conv2d, 512, [3, 3], scope='conv4')
                net = layer('pool4', slim.max_pool2d, net, [2, 2], scope='pool4')
                net = layer('conv5', slim.repeat,     net, 4, slim.conv2d, 512, [3, 3], scope='conv5')
                net = layer('pool5', slim.max_pool2d, net, [2, 2], scope='pool5')

                # Use conv2d instead of fully_connected layers.
                net = layer('fc6',      slim.conv2d,  net, 4096, [7, 7], padding=fc_conv_padding, scope='fc6')
                net = layer('dropout6', slim.dropout, net, self.config.dropout,
                            is_training=self.config.is_training,
                            scope='dropout6')
                net = layer('fc7',      slim.conv2d,  net, 4096, [1, 1], scope='fc7')
                net = layer('dropout7', slim.dropout, net, self.config.dropout,
                            is_training=self.config.is_training,
                            scope='dropout7')

                if should_be_extended:
                    return

                net = layer('fc8',      slim.conv2d,  net, self.config.num_classes, [1, 1],
                            activation_fn=None,
                            normalizer_fn=None,
                            scope='fc8')

                if spatial_squeeze:
                    layer('fc8', tf.squeeze, net, [1, 2], name='fc8_squeezed')